
\section*{An Informal Overview}

\paragraph*{Why another PRA solver?}
\acrfull{pra} for large nuclear systems asks a simple
question: \emph{how likely is an accident, given thousands of component
failures, recoveries, and human actions?} The textbook solution (build a decision diagram, or enumerate every failure combination) scales exponentially and quickly becomes impractical. Over the years analysts have tamed that
combinatorial surge with gate restrictions, bounding tricks, and
rare-event approximations; the price has been either coarse error
margins or hours‐long runtimes.


\paragraph*{A different stance: sample first, ask questions later.}
Instead of traversing every Boolean state, we draw random global
scenarios and evaluate the entire logic graph in one pass.
The key enabler is hardware parallelism: by packing \(64\)
Bernoulli trials into a 64-bit word we turn Boolean gates into
bitwise instructions and let modern \acrfull{gpu}s churn through billions of
scenarios per second. The solver, \textsc{mcScram}, views the complete
PRA model (nested event trees, fault trees, and their cross-links) as
one unified \acrfull{pdag} that is sampled
and tallied en bloc.

\paragraph*{What falls out of that design?}
\begin{itemize}
  \item \textbf{Flexibility.}  Any gate expressible in Boolean logic
        (NOT, \(k\)-out-of-\(n\) voting, \acrshort{xor}, Cardinality, \dots) is handled
        without extra coding.
  \item \textbf{Speed.}  On a mid-range laptop \acrshort{gpu} the method converges
        to sub-percent error for graphs with a few thousand events in
        \(\lesssim 5\) seconds.
  \item \textbf{Extensibility.}  Because sampling is the only primitive,
        common-cause failures, importance measures, and importance
        sampling plug in naturally.
\end{itemize}

\paragraph*{What it is \emph{not}.}
The approach is still Monte-Carlo: for events rarer than
\(10^{-8}\) additional variance-reduction techniques are required, and
maximum throughput depends on access to a \acrshort{gpu} or other \acrfull{simd} hardware. It is also \emph{not} an exact Boolean enumerator. By design we trade exactness for tractability and streamability: outputs are stochastic estimators with on-line confidence intervals that tighten as sample size grows. Practitioners must therefore choose a target error band and be comfortable with the residual uncertainty when stopping.



\paragraph*{Road map.}
\begin{itemize}
  \item \textbf{Chapter 4 (Part I).} Formalizes \acrshort{pra} models as probabilistic \acrshort{dag}s. 
  \item \textbf{Chapters 7–11 (Part \ref{part_brute_force}).} Present the data-parallel Monte-Carlo engine—sampling, gate kernels, tallying, and backend scalability. 
  \item \textbf{Chapters 13–18 (Part \ref{part_refinements}).} Detail refinements: randomness guarantees, composite convergence policy, common-cause failure handling, importance measures, importance sampling, and hardware-native voting gates. 
  \item \textbf{Chapters 12 and 19.} Benchmark accuracy, runtime, and structural compression on the Aralia suite. 
  \item \textbf{Part \ref{part_inverse_problems}.} Outlines future directions such as inverse problems and parameter fitting.
\end{itemize}

\clearpage