\chapter{Tallying Layer Outputs}
\label{sec:tally_kernel}

At every Monte-Carlo iteration the simulator produces, for each logic node
\(v\in \mathcal{V}\), a bit-packed buffer encoding
\[
  \mathbf{Y}_v^{(t)}
  \;=\;
  \bigl(y_{v,1}^{(t)}, y_{v,2}^{(t)},\dots, y_{v,N}^{(t)}\bigr)
  \in\{0,1\}^N,
  \quad t = 1,\dots,T,
\]
where \(N\!=\!B\!\times\!P\!\times\!\omega\) is the number of Bernoulli trials
per Monte-Carlo \emph{iteration}:
\begin{itemize}
    \item \(B\) - number of \emph{batches},
    \item \(P\) - bit-packs per batch,
    \item \(\omega\!=\!8\cdot\mathrm{sizeof}(\text{bitpack\_t})\) - bits per pack.
\end{itemize}
Because the buffers are overwritten at the next iteration, a
separate \emph{tally layer} accumulates summary statistics that persist for the
entire simulation.  The present section formalizes that process and outlines
an implementation-agnostic, data-parallel algorithm that realizes it on modern
accelerators.

\section{Statistical Objectives}
\label{subsec:tally_objective}

For every node \(v\) we wish to estimate, after \(T\) Monte-Carlo iterations,

\[
  \widehat{p}_v
  \;=\;
  \frac{1}{T\,N}
  \sum_{t=1}^{T}\sum_{j=1}^{N} y_{v,j}^{(t)}
  \;=\;
  \frac{s_v}{T\,N},
  \qquad
  s_v \;=\; \text{total \# of one-bits observed for node \(v\)}.
\]

Under the usual independence assumptions, the sampling distribution of
\(\widehat{p}_v\) is asymptotically
\[
\mathcal{N}\!\bigl(p_v,\,
  \tfrac{p_v(1-p_v)}{T\,N}\bigr)
\]
Hence

\[
  \widehat{\sigma}_v
  \;=\;
  \sqrt{\frac{\widehat{p}_v\,(1-\widehat{p}_v)}{T\,N}}
\]

is an unbiased estimator of the standard error, giving the
\((1-\alpha)\)\,--\,level normal confidence interval

\[
  \bigl[
    \widehat{p}_v - z_{1-\alpha/2}\,\widehat{\sigma}_v,\;
    \widehat{p}_v + z_{1-\alpha/2}\,\widehat{\sigma}_v
  \bigr],
  \qquad
  z_{1-\alpha/2}\in\{1.96,\,2.58,\dots\}.
\]

The tally routine therefore needs to maintain only the scalar
\(s_v\) while the simulation is running; the derived statistics can be updated
in-place whenever a user requests intermediate results or at a fixed cadence.

\section{Parallel Accumulation Algorithm}

The accumulation kernel is invoked on a three-dimensional
\texttt{nd\_range}, chosen such that
\[
  \begin{aligned}
    \text{global}_x &\;\ge\; V,\\
    \text{global}_y &\;\ge\; B,\\
    \text{global}_z &\;\ge\; P.
  \end{aligned}
\]
Work-item \((i_x,i_y,i_z)\) is responsible for \emph{exactly one} bit-pack:
\[
  \text{node  } v=i_x,\quad
  \text{batch } b=i_y,\quad
  \text{pack  } p=i_z.
\]

\vspace{4pt}
\noindent
\textbf{Local workflow of a work-item}
\begin{enumerate}
    \item Load the \(p^{\text{th}}\) bit-pack of batch \(b\) from
          \texttt{buffer}.
    \item Compute \(c=\mathrm{popcount}(\text{bitpack})\).
    \item Reduce the \(c\)'s belonging to the same work-\emph{group} in
          shared memory (tree reduction or \texttt{reduce\_over\_group}).
    \item One designated leader performs
          \(\texttt{atomic\_add}(\texttt{num\_one\_bits},\,\text{group\_sum})\).
\end{enumerate}

The reduction ensures only one atomic operation per group, greatly reducing
contention when \(P\) is large.

We present platform-neutral pseudocode that encapsulates the above logic while remaining agnostic to the underlying API. After each Monte-Carlo iteration the host enqueues \textsc{TallyKernel} with a
fresh \texttt{iteration} counter.  When either (i)~a user requests
intermediate statistics or (ii)~a pre-set reporting interval is reached,
the host reads back \texttt{num\_one\_bits} and executes the purely
serial routine shown in Algorithm~\ref{alg:update_stats}.

\begin{algorithm}[H]
\caption{Post-processing of a single node's tally}
\label{alg:update_stats}
\begin{algorithmic}[1]
  \Require
    \(s\) - total one-bits,
    \(T\), \(B\), \(P\), \(\omega\) - run parameters
  \Ensure
    \(\widehat{p}\), \(\widehat{\sigma}\), two symmetric CIs
  \State $N\gets B\cdot P\cdot\omega$
  \State $\widehat{p}\gets s / (T\,N)$
  \State $\widehat{\sigma}\gets
          \sqrt{\widehat{p}(1-\widehat{p})/(T\,N)}$
  \For{\textbf{each} $z\in\{1.96,\,2.58\}$}
      \State $\text{CI}\gets
        \bigl[\max(0,\widehat{p}-z\widehat{\sigma}),
              \min(1,\widehat{p}+z\widehat{\sigma})\bigr]$
  \EndFor
\end{algorithmic}
\end{algorithm}

The above normal approximation is valid provided \(T\,N\widehat{p}\)
and \(T\,N(1-\widehat{p})\) both exceed roughly 10; otherwise an exact
Clopper-Pearson interval can be substituted with no change to the running
sum logic.

\section{Correctness and Complexity}

\textbf{Work-item cost.}
Each work-item performs one \(\mathrm{popcount}\) and
participates in an \(O(\log L)\) intra-group reduction
(\(L\!=\!\text{local\_range}\)), yielding an overall
\(O(\log L)\) instruction count.

\textbf{Global cost.}
The total number of work-items launched per iteration is
\(V\cdot B\cdot P\).  Because each bit-pack contains \(\omega\) Bernoulli
trials, the cost \emph{per trial} shrinks as \(\omega^{-1}\).

\textbf{Memory traffic.}
Every work-item reads exactly one machine word and no writes occur except
the single atomic addition per work-group.  Hence the algorithm is
memory-bandwidth bound only at extremely low arithmetic intensity
(\(P\approx 1\)).

\textbf{Linear scalability.}
All tally nodes are independent.  Increasing \(V\) therefore scales the total
runtime linearly until either (i)~the device saturates its occupancy or
(ii)~atomic contention becomes non-negligible; the group-level reduction
mitigates the latter.

The design therefore provides a clear separation of concerns: depth--first
analysis establishes the dependency structure; kernel generation translates
that structure into homogeneous, vectorizable work; and a light--weight event
system schedules the resulting kernels with minimal host intervention.

% -----------------------------------------------------------------------------
%  Extended implementation-oriented discussion (matches the realised kernel)
% -----------------------------------------------------------------------------

\section{Work--Group Geometry and Synchronization}
\label{subsec:tally_geometry}

The three--dimensional launch geometry \((v,\,b,\,p)\) outlined in
Sec.~\ref{subsec:tally_objective} is refined in the implementation to minimize
both occupancy loss and atomic contention.  A crucial design choice is to fix
\emph{local}~\(x=1\), thereby dedicating one work--group to exactly one tally
node~\(v\).  The remaining two dimensions then tile the \((b,p)\)--plane with a
rectangular block of size
\[
  \bigl(1,\,l_y,\,l_z\bigr),
  \qquad l_y\cdot l_z\le L_{\max},
\]
where \(L_{\max}\) is the device--specific upper bound on the total work--group
size.  Provided \(l_y\!\ge\!B\) and \(l_z\!\ge\!P\), only \emph{one} group is
dispatched per tally and per iteration, guaranteeing that the reduction of
Step~3 and the atomic addition of Step~4 in
Sec.~\ref{sec:tally_kernel} execute exactly once.  Should resource pressure
force \(l_y< B\) or \(l_z< P\), multiple groups are launched and the atomic
update is replicated; correctness is preserved by the commutativity of
addition, but the repeated work incurs a small overhead.  The occupancy model
therefore trades a moderate loss in parallelism for deterministic behavior and
reduced synchronization cost.

A relaxed memory order is sufficient for the atomic accumulator because the
kernel guarantees \emph{program order} between the intra--group reduction and
the atomic~\texttt{fetch\_add}.  No additional fences are required, and the
resulting implementation maps efficiently to both discrete and integrated
\acrshort{gpu}s.

\section{Incremental Update of Derived Statistics}
\label{subsec:tally_stats_refresh}

While Monte--Carlo sampling proceeds, applications often request intermediate
probability estimates~\(\widehat{p}_v^{(t)}\) before the total budget~\(T\) is
exhausted.  Recomputing \(\widehat{p}_v\) and
\(\widehat{\sigma}_v\) from scratch would require a host round--trip for every
sampled bit.  Instead, the tally layer maintains two scalars per node:
\(s_v\) (total one--bits) and \(n_v\) (total bits processed).  After each
completed iteration the host merely increments \(n_v\gets n_v + N\) and leaves
\(s_v\) to the device kernel.  Whenever a refresh is requested the statistics
are updated via
\[
  \widehat{p}_v\;=\;\frac{s_v}{n_v},
  \qquad
  \widehat{\sigma}_v\;=\;\sqrt{\frac{\widehat{p}_v(1-\widehat{p}_v)}{n_v}},
\]
which costs \(\mathcal{O}(V)\) host--side arithmetic and no device work.  In
practice the refresh cadence is set adaptively: frequent updates early in the
run aid variance monitoring, whereas late--stage updates can be spaced further
apart because the relative change in \(\widehat{p}_v\) diminishes as
\(n_v\to T\,N\).

\section{Convergence Diagnostics and Stopping Rules}
\label{subsec:tally_convergence}

Two families of diagnostics leverage the quantities already maintained by the
tally kernel:
\begin{enumerate}
  \item\textbf{Relative half--width criterion.}  Define the
        half--width of the \((1-\alpha)\)--level interval as
        \(h_v= z_{1-\alpha/2}\,\widehat{\sigma}_v\).  The run may be terminated
        for node~\(v\) once \(h_v/\widehat{p}_v\le \varepsilon\), where
        \(\varepsilon\) is a user--supplied tolerance.  Because both
        \(\widehat{\sigma}_v\) and \(\widehat{p}_v\) are inexpensive to update,
        the test incurs negligible overhead.
  \item\textbf{Sequential Wald test.}  When the goal is to decide whether
        \(p_v\) exceeds a safety threshold~\(p_0\), one may adopt the
        sequential probability ratio test with boundaries derived from
        \(s_v\) and \(n_v\).  The tally structure already provides the minimal
        sufficient statistics, so the host evaluates the Wald condition after
        every refresh with no additional device interaction.
\end{enumerate}
Because the diagnostics rely solely on \(s_v\) and \(n_v\), no modification to
the kernel is needed; all logic resides in a lightweight host callback.

\section{Implementation Cost Model}
\label{subsec:tally_cost_model}

Let \(C_{\mathrm{pc}}\) denote the latency of a hardware popcount and
\(C_{\mathrm{rd}}(l)\) the latency of a tree reduction over \(l\) work--items.
The wall--clock time per iteration is approximated by
\[
  T_{\text{iter}} \;\approx\;
  (C_{\mathrm{pc}} + C_{\mathrm{mem}})\,VBP +
  C_{\mathrm{rd}}(l_y l_z)\,\frac{VBP}{l_y l_z}
  + C_{\mathrm{atomic}}\,\frac{VBP}{l_y l_z},
\]
where \(C_{\mathrm{mem}}\) and \(C_{\mathrm{atomic}}\) are the per--word memory
and atomic latencies, respectively.  The model highlights two regimes:
\begin{itemize}
  \item\emph{Arithmetic bound}: when \(P\gg 1\) and the popcount throughput
        saturates the execution units, the first term dominates and scaling is
        limited by instruction bandwidth.
  \item\emph{Memory bound}: when \(P\approx 1\) the workload collapses to a
        single read per work--item; the kernel becomes memory bandwidth--
        limited as predicted in Sec.~\ref{subsec:tally_objective}.
\end{itemize}


\section{Numerical Robustness}
\label{subsec:tally_numerics}

All accumulators operate in integer arithmetic, thereby eliminating rounding
error in \(s_v\).  Derived quantities computed in double precision satisfy
\(\lvert\widehat{p}_v - s_v/n_v\rvert < 2^{-53}\), well below any practical
error criterion for reliability analysis.  Clamping the confidence interval
bounds to~\([0,1]\) prevents pathological estimates when either \(s_v=0\) or
\(s_v=n_v\) in early iterations.

% -----------------------------------------------------------------------------
\section{Relation to the Global Execution Model}
\label{subsec:tally_exec_relation}

The specialised geometry adopted in Section~\ref{subsec:tally_geometry} is a direct instantiation of the rules formalised in Section~\ref{sec:kernel_execution_model}.  Choosing $L_x=1$ enforces the work\,–\,group invariant whereby a group owns exactly one tally node while still satisfying
\[
   G_x \;=\; \Bigl\lceil \frac{V}{L_x} \Bigr\rceil L_x \;=\; V ,
\]
so no over-provisioning occurs along the $x$-axis.  The remaining dimensions follow the generic rounding scheme with $(Q_y,Q_z)=(B,P)$, thus preserving the one-to-one correspondence between work-items and bit-packs established in Section~\ref{sec:kernel_execution_model}.